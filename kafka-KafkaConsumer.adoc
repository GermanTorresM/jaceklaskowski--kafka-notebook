== [[KafkaConsumer]] KafkaConsumer

`KafkaConsumer` is the main class that you will use to write link:kafka-consumers.adoc[Kafka consumers].

[source, scala]
----
// sandbox/kafka-sandbox
val configs: Map[String, Object] = Map(
  // required properties
  ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG -> bootstrapServers,
  ConsumerConfig.GROUP_ID_CONFIG -> groupId
)
import org.apache.kafka.common.serialization.StringDeserializer
val keyDeserializer = new StringDeserializer
val valueDeserializer = new StringDeserializer

import scala.collection.JavaConverters._
import org.apache.kafka.clients.consumer.KafkaConsumer
val consumer = new KafkaConsumer[String, String](
  configs.asJava,
  keyDeserializer,
  valueDeserializer)
----

NOTE: `KafkaConsumer` is not safe for multi-threaded access and so you should use a single thread per instance.

`KafkaConsumer` registers itself in JMX with *kafka.consumer* prefix.

CAUTION: FIXME How does the JMX registration happen?

[[internal-registries]]
.KafkaConsumer's Internal Registries and Counters
[cols="1,2",options="header",width="100%"]
|===
| Name
| Description

| [[client]] `client`
| link:kafka-ConsumerNetworkClient.adoc[ConsumerNetworkClient]

Used when...FIXME

| [[clientId]] `clientId`
|

| [[fetcher]] `fetcher`
| link:kafka-Fetcher.adoc[Fetcher]

Used when...FIXME

| [[interceptors]] `interceptors`
| `ConsumerInterceptors` that holds link:kafka-ConsumerInterceptor.adoc[ConsumerInterceptor] instances (defined using link:kafka-properties.adoc#interceptor.classes[interceptor.classes] setting).

Used when...FIXME

| [[metadata]] `metadata`
| link:kafka-Metadata.adoc[Metadata]

Created right when `KafkaConsumer` is <<creating-instance, created>>.

Used when...FIXME

| [[metrics]] `metrics`
| `Metrics`

| [[retryBackoffMs]] `retryBackoffMs`
| link:kafka-properties-retry-backoff-ms.adoc[retry.backoff.ms] property or a user-defined value

| [[requestTimeoutMs]] `requestTimeoutMs`
a|

`KafkaConsumer` reports `ConfigException` when smaller or equal than link:kafka-properties.adoc#session_timeout_ms[session.timeout.ms] and link:kafka-properties.adoc#fetch_max_wait_ms[fetch.max.wait.ms] properties.

| [[subscriptions]] `subscriptions`
| `SubscriptionState` for link:kafka-properties.adoc#auto.offset.reset[auto.offset.reset] setting.

Created when `KafkaConsumer` <<creating-instance, is created>>.
|===

[TIP]
====
Enable `DEBUG` or `TRACE` logging levels for `org.apache.kafka.clients.consumer.KafkaConsumer` logger to see what happens inside.

Add the following line to `config/tools-log4j.properties`:

```
log4j.logger.org.apache.kafka.clients.consumer.KafkaConsumer=TRACE
```

Refer to link:kafka-logging.adoc[Logging].
====

=== [[pollOnce]] Polling Once for ConsumerRecords per TopicPartition -- `pollOnce` Internal Method

CAUTION: FIXME

=== [[poll]] Poll Specified Milliseconds For ConsumerRecords per TopicPartitions -- `poll` Method

[source, java]
----
ConsumerRecords<K, V> poll(long timeout)
----

`poll` polls for new records until `timeout` expires.

NOTE: The input `timeout` should be `0` or greater and is the milliseconds to poll for records.

Internally, `poll` <<pollOnce, polls once>> (for ConsumerRecords per TopicPartitions).

If there are records fetched, `poll` checks <<fetcher, Fetcher>> for `sendFetches` or <<client, ConsumerNetworkClient>> for `pendingRequestCount` and, when either is positive, requests <<client, ConsumerNetworkClient>> to `pollNoWakeup`.

CAUTION: FIXME Make the above more user-friendly

`poll` returns the fetched `ConsumerRecords` when no `interceptors` are defined or passes them on to `ConsumerInterceptors` using `onConsume`

CAUTION: FIXME Make the above more user-friendly, e.g. when could `interceptors` be empty?

NOTE: `poll` is a part of link:kafka-consumers.adoc#poll[Consumer contract] to...FIXME

=== [[creating-instance]] Creating KafkaConsumer Instance

`KafkaConsumer` takes the following when created:

* [[configs]] Consumer configuration (that is converted internally to link:kafka-ConsumerConfig.adoc[ConsumerConfig])
* [[keyDeserializer]] link:kafka-Deserializer.adoc[Deserializer] for keys
* [[valueDeserializer]] link:kafka-Deserializer.adoc[Deserializer] for values

`KafkaConsumer` initializes the <<internal-registries, internal registries and counters>>.

NOTE: `KafkaConsumer` API offers other constructors that in the end use the <<creating-instance-public, public 3-argument constructor>> that in turn passes the call on to the <<creating-instance-internal, private internal constructor>>.

==== [[creating-instance-public]] KafkaConsumer Public Constructor

[source, java]
----
// Public API
KafkaConsumer(
  Map<String, Object> configs,
  Deserializer<K> keyDeserializer,
  Deserializer<V> valueDeserializer)
----

When created, `KafkaConsumer` adds the <<keyDeserializer, keyDeserializer>> and <<valueDeserializer, valueDeserializer>> to <<configs, configs>> (as link:kafka-properties.adoc#key.deserializer[key.deserializer] and link:kafka-properties.adoc#value.deserializer[value.deserializer] properties respectively) and creates a link:kafka-ConsumerConfig.adoc[ConsumerConfig].

`KafkaConsumer` passes the call on to the <<creating-instance-internal, internal constructor>>.

==== [[creating-instance-internal]] KafkaConsumer Internal Constructor

[source, java]
----
KafkaConsumer(
  ConsumerConfig config,
  Deserializer<K> keyDeserializer,
  Deserializer<V> valueDeserializer)
----

When called, the internal `KafkaConsumer` constructor prints out the following DEBUG message to the logs:

```
DEBUG Starting the Kafka consumer
```

`KafkaConsumer` sets the internal <<requestTimeoutMs, requestTimeoutMs>> to <<request_timeout_ms, request.timeout.ms>> property.

`KafkaConsumer` sets the internal <<clientId, clientId>> to link:kafka-properties.adoc#client.id[client.id] or generates one with prefix *consumer-* (starting from 1) if not set.

`KafkaConsumer` sets the internal <<metrics, Metrics>> (and `JmxReporter` with *kafka.consumer* prefix).

`KafkaConsumer` sets the internal <<retryBackoffMs, retryBackoffMs>> to link:kafka-properties.adoc#retry.backoff.ms[retry.backoff.ms] property.

CAUTION: FIXME Finish me!

`KafkaConsumer` creates the internal <<metadata, Metadata>> with the following arguments:

1. <<retryBackoffMs, retryBackoffMs>>
1. link:kafka-properties.adoc#metadata.max.age.ms[metadata.max.age.ms]
1. `allowAutoTopicCreation` enabled
1. `topicExpiryEnabled` disabled
1. `ClusterResourceListeners` with user-defined list of link:kafka-ConsumerInterceptor.adoc[ConsumerInterceptors] in link:kafka-properties.adoc#interceptor.classes[interceptor.classes] property

`KafkaConsumer` link:kafka-Metadata.adoc#update[updates] `metadata` with link:kafka-properties.adoc#bootstrap.servers[bootstrap.servers].

CAUTION: FIXME Finish me!

`KafkaConsumer` creates a link:kafka-NetworkClient.adoc[NetworkClient] with...FIXME

CAUTION: FIXME Finish me!

In the end, `KafkaConsumer` prints out the following DEBUG message to the logs:

```
DEBUG Kafka consumer created
```

Any issues while creating a `KafkaConsumer` are reported as `KafkaException`.

```
org.apache.kafka.common.KafkaException: Failed to construct kafka consumer
```
