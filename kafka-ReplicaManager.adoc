== [[ReplicaManager]] ReplicaManager

`ReplicaManager` is <<creating-instance, created>> and <<startup, started>> when `KafkaServer` link:kafka-KafkaServer.adoc#startup[starts up].

When <<startup, started>>, `ReplicaManager` schedules <<isr-expiration, isr-expiration>> and <<isr-change-propagation, isr-change-propagation>> recurring tasks (every half of link:kafka-properties.adoc#replica.lag.time.max.ms[replica.lag.time.max.ms] property and 2500 ms, respectively).

`ReplicaManager` is a `KafkaMetricsGroup`.

[[internal-registries]]
.ReplicaManager's Internal Properties (e.g. Registries and Counters)
[frame="topbot",cols="1,2",options="header",width="100%"]
|===
| Name
| Description

| [[allPartitions]] `allPartitions`
| Pool of `TopicPartition` and link:kafka-Partition.adoc[Partitions]

| [[isrChangeSet]] `isrChangeSet`
| Collection of `TopicPartition` that...FIXME

| [[lastIsrChangeMs]] `lastIsrChangeMs`
| Time when <<isrChangeSet, isrChangeSet>> has a new `TopicPartition` <<recordIsrChange, added>>.

| [[logDirFailureHandler]] `logDirFailureHandler`
| link:kafka-LogDirFailureHandler.adoc[LogDirFailureHandler]

| [[OfflinePartition]] `OfflinePartition`
|
|===

=== [[recordIsrChange]] `recordIsrChange` Method

[source, scala]
----
recordIsrChange(topicPartition: TopicPartition): Unit
----

`recordIsrChange` adds the input `topicPartition` to <<isrChangeSet, isrChangeSet>> internal registry and sets <<lastIsrChangeMs, lastIsrChangeMs>> to the current time.

NOTE: `recordIsrChange` is used exclusively when `Partition` does link:kafka-Partition.adoc#updateIsr[updateIsr]

=== [[updateFollowerLogReadResults]] `updateFollowerLogReadResults` Internal Method

[source, scala]
----
updateFollowerLogReadResults(
  replicaId: Int,
  readResults: Seq[(TopicPartition, LogReadResult)]): Seq[(TopicPartition, LogReadResult)]
----

`updateFollowerLogReadResults`...FIXME

NOTE: `updateFollowerLogReadResults` is used exclusively when `ReplicaManager` <<fetchMessages, fetches messages from the leader replica>>.

=== [[fetchMessages]] `fetchMessages` Method

[source, scala]
----
fetchMessages(
  timeout: Long,
  replicaId: Int,
  fetchMinBytes: Int,
  fetchMaxBytes: Int,
  hardMaxBytesLimit: Boolean,
  fetchInfos: Seq[(TopicPartition, FetchRequest.PartitionData)],
  quota: ReplicaQuota = UnboundedQuota,
  responseCallback: Seq[(TopicPartition, FetchPartitionData)] => Unit,
  isolationLevel: IsolationLevel): Unit
----

`fetchMessages`...FIXME

NOTE: `fetchMessages` is used exclusively when `KafkaApis` link:kafka-KafkaApis.adoc#handleFetchRequest[handles a Fetch request].

=== [[getLeaderPartitions]] `getLeaderPartitions` Internal Method

[source, scala]
----
getLeaderPartitions: List[Partition]
----

`getLeaderPartitions` gives the partitions from <<allPartitions, allPartitions>> that are not <<OfflinePartition, offline>> and their leaderReplicaIfLocal property is defined.

NOTE: `getLeaderPartitions` is used when...FIXME

=== [[isr-expiration]] `isr-expiration` Task

CAUTION: FIXME

=== [[isr-change-propagation]] `isr-change-propagation` Task

CAUTION: FIXME

=== [[maybePropagateIsrChanges]] `maybePropagateIsrChanges` Method

[source, scala]
----
maybePropagateIsrChanges(): Unit
----

`maybePropagateIsrChanges`...FIXME

NOTE: `maybePropagateIsrChanges` is used exclusively when <<isr-change-propagation, isr-change-propagation>> task is executed (every 2500 milliseconds).

=== [[creating-instance]] Creating ReplicaManager Instance

`ReplicaManager` takes the following when created:

* [[config]] link:kafka-KafkaConfig.adoc[KafkaConfig]
* [[metrics]] `Metrics`
* [[time]] `Time`
* [[zkUtils]] link:kafka-ZkUtils.adoc[ZkUtils]
* [[scheduler]] `Scheduler`
* [[logManager]] link:kafka-LogManager.adoc[LogManager]
* [[isShuttingDown]] `isShuttingDown` flag
* [[quotaManager]] `ReplicationQuotaManager`
* [[brokerTopicStats]] `BrokerTopicStats`
* [[metadataCache]] link:kafka-MetadataCache.adoc[MetadataCache]
* [[logDirFailureChannel]] `LogDirFailureChannel`
* [[delayedProducePurgatory]] `DelayedOperationPurgatory[DelayedProduce]`
* [[delayedFetchPurgatory]] `DelayedOperationPurgatory[DelayedFetch]`
* [[delayedDeleteRecordsPurgatory]] `DelayedOperationPurgatory[DelayedDeleteRecords]`
* [[threadNamePrefix]] Optional thread name prefix

`ReplicaManager` initializes the <<internal-registries, internal registries and counters>>.

=== [[startup]] Starting ReplicaManager (and Scheduling ISR-Related Tasks) -- `startup` Method

[source, scala]
----
startup(): Unit
----

`startup` requests <<scheduler, Scheduler>> to link:kafka-KafkaScheduler.adoc#schedule[schedule the ISR-related tasks]:

1. <<isr-expiration, isr-expiration>>
2. <<isr-change-propagation, isr-change-propagation>>

`startup` then creates a <<logDirFailureHandler, LogDirFailureHandler>> and requests it to link:kafka-LogDirFailureHandler.adoc#start[start].

NOTE: `startup` uses `Scheduler` that was specified when `ReplicaManager` <<creating-instance, was created>>.

NOTE: `startup` is used exclusively when `KafkaServer` link:kafka-KafkaServer.adoc#startup[starts up].

=== [[maybeShrinkIsr]] `maybeShrinkIsr` Internal Method

[source, scala]
----
maybeShrinkIsr(): Unit
----

`maybeShrinkIsr` prints out the following TRACE message to the logs:

```
TRACE Evaluating ISR list of partitions to see which replicas can be removed from the ISR
```

`maybeShrinkIsr` requests the partitions (from <<allPartitions, allPartitions>> pool that are not <<OfflinePartition, offline partitions>>) to link:kafka-Partition.adoc#maybeShrinkIsr[maybeShrinkIsr] (with link:kafka-KafkaConfig.adoc#replicaLagTimeMaxMs[replicaLagTimeMaxMs] property).

NOTE: `maybeShrinkIsr` is used exclusively to schedule `isr-expiration` recurring task when `ReplicaManager` <<startup, starts up>>.
