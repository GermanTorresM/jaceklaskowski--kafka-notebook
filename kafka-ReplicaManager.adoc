== [[ReplicaManager]] ReplicaManager

`ReplicaManager` is <<creating-instance, created>> and <<startup, started>> when `KafkaServer` is requested to link:kafka-KafkaServer.adoc#startup[start].

When <<startup, started>>, `ReplicaManager` schedules <<isr-expiration, isr-expiration>> and <<isr-change-propagation, isr-change-propagation>> recurring tasks.

`ReplicaManager` is a `KafkaMetricsGroup`.

[[internal-registries]]
.ReplicaManager's Internal Registries and Counters
[frame="topbot",cols="1,2",options="header",width="100%"]
|===
| Name
| Description

| [[allPartitions]] `allPartitions`
| Pool of `TopicPartition` and link:kafka-Partition.adoc[Partitions]

| [[logDirFailureHandler]] `logDirFailureHandler`
| link:kafka-LogDirFailureHandler.adoc[LogDirFailureHandler]

| [[OfflinePartition]] `OfflinePartition`
|
|===

=== [[getLeaderPartitions]] `getLeaderPartitions` Internal Method

[source, scala]
----
getLeaderPartitions: List[Partition]
----

`getLeaderPartitions` gives the partitions from <<allPartitions, allPartitions>> that are not <<OfflinePartition, offline>> and their leaderReplicaIfLocal property is defined.

NOTE: `getLeaderPartitions` is used

=== [[maybePropagateIsrChanges]] `maybePropagateIsrChanges` Method

CAUTION: FIXME

=== [[isr-expiration]] `isr-expiration` Task

CAUTION: FIXME

=== [[isr-change-propagation]] `isr-change-propagation` Task

CAUTION: FIXME

=== [[creating-instance]] Creating ReplicaManager Instance

`ReplicaManager` takes the following when created:

* [[config]] link:kafka-KafkaConfig.adoc[KafkaConfig]
* [[metrics]] `Metrics`
* [[time]] `Time`
* [[zkUtils]] link:kafka-ZkUtils.adoc[ZkUtils]
* [[scheduler]] `Scheduler`
* [[logManager]] link:kafka-LogManager.adoc[LogManager]
* [[isShuttingDown]] `isShuttingDown` flag
* [[quotaManager]] `ReplicationQuotaManager`
* [[brokerTopicStats]] `BrokerTopicStats`
* [[metadataCache]] link:kafka-MetadataCache.adoc[MetadataCache]
* [[logDirFailureChannel]] `LogDirFailureChannel`
* [[delayedProducePurgatory]] `DelayedOperationPurgatory[DelayedProduce]`
* [[delayedFetchPurgatory]] `DelayedOperationPurgatory[DelayedFetch]`
* [[delayedDeleteRecordsPurgatory]] `DelayedOperationPurgatory[DelayedDeleteRecords]`
* [[threadNamePrefix]] Optional thread name prefix

`ReplicaManager` initializes the <<internal-registries, internal registries and counters>>.

=== [[startup]] Starting ReplicaManager (and Scheduling ISR-Related Tasks) -- `startup` Method

[source, scala]
----
startup(): Unit
----

`startup` requests <<scheduler, Scheduler>> to link:kafka-KafkaScheduler.adoc#schedule[schedule the ISR-related tasks]:

1. <<isr-expiration, isr-expiration>>
2. <<isr-change-propagation, isr-change-propagation>>

`startup` then creates a <<logDirFailureHandler, LogDirFailureHandler>> and requests it to link:kafka-LogDirFailureHandler.adoc#start[start].

NOTE: `startup` uses `Scheduler` that was specified when `ReplicaManager` <<creating-instance, was created>>.

NOTE: `startup` is used exclusively when `KafkaServer` link:kafka-KafkaServer.adoc#startup[starts up].

=== [[maybeShrinkIsr]] `maybeShrinkIsr` Internal Method

[source, scala]
----
maybeShrinkIsr(): Unit
----

`maybeShrinkIsr` prints out the following TRACE message to the logs:

```
TRACE Evaluating ISR list of partitions to see which replicas can be removed from the ISR
```

`maybeShrinkIsr` requests the partitions (from <<allPartitions, allPartitions>> pool that are not <<OfflinePartition, offline partitions>>) to link:kafka-Partition.adoc#maybeShrinkIsr[maybeShrinkIsr] (with link:kafka-KafkaConfig.adoc#replicaLagTimeMaxMs[replicaLagTimeMaxMs] setting).

NOTE: `maybeShrinkIsr` is used exclusively to schedule `isr-expiration` recurring task when `ReplicaManager` <<startup, starts up>>.
