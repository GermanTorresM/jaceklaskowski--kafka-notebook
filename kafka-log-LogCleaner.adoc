== [[LogCleaner]] LogCleaner

`LogCleaner` is <<creating-instance, created>> exclusively when `LogManager` is <<kafka-log-LogManager.adoc#cleaner, created>> (with `enableCleaner` enabled which is the default).

When <<creating-instance, created>>, `LogCleaner` is given a <<config, CleanerConfig>> that `LogManager` <<cleanerConfig, builds>> when <<kafka-log-LogManager.adoc#apply, created>> (when `KafkaServer` is requested to <<kafka-server-KafkaServer.adoc#startup, start up>>).

`LogCleaner` is a <<kafka-metrics-KafkaMetricsGroup.adoc#, KafkaMetricsGroup>> and registers <<metrics, performance metrics>>.

[[metrics]]
.LogCleaner's Performance Metrics
[cols="1m,2",options="header",width="100%"]
|===
| Metric Name
| Description

| max-buffer-utilization-percent
| [[max-buffer-utilization-percent]]

| cleaner-recopy-percent
| [[cleaner-recopy-percent]]

| max-clean-time-secs
| [[max-clean-time-secs]]

|===

The <<metrics, performance metrics>> are registered in *kafka.log:type=LogCleaner* group.

.LogCleaner in jconsole
image::images/LogCleaner-jconsole.png[align="center"]

[[reconfigurableConfigs]]
`LogCleaner` is a <<kafka-server-BrokerReconfigurable.adoc#, BrokerReconfigurable>> for the following <<kafka-server-BrokerReconfigurable.adoc#reconfigurableConfigs, dynamic configurations>>:

* <<kafka-server-KafkaConfig.adoc#LogCleanerThreadsProp, log.cleaner.threads>>

* <<kafka-server-KafkaConfig.adoc#LogCleanerDedupeBufferSizeProp, log.cleaner.dedupe.buffer.size>>

* <<kafka-server-KafkaConfig.adoc#LogCleanerDedupeBufferLoadFactorProp, log.cleaner.io.buffer.load.factor>>

* <<kafka-server-KafkaConfig.adoc#LogCleanerIoBufferSizeProp, log.cleaner.io.buffer.size>>

* <<kafka-server-KafkaConfig.adoc#LogCleanerIoMaxBytesPerSecondProp, log.cleaner.io.max.bytes.per.second>>

* <<kafka-server-KafkaConfig.adoc#LogCleanerBackoffMsProp, log.cleaner.backoff.ms>>

* <<kafka-server-KafkaConfig.adoc#MessageMaxBytesProp, message.max.bytes>>

[[internal-registries]]
.LogCleaner's Internal Properties (e.g. Registries, Counters and Flags)
[cols="1m,3",options="header",width="100%"]
|===
| Name
| Description

| cleaners
a| [[cleaners]] <<kafka-log-CleanerThread.adoc#, CleanerThreads>>

Used when...FIXME

| config
a| [[config]][[currentConfig]] <<CleanerConfig, CleanerConfig>>

Initialized with the given <<initialConfig, CleanerConfig>>

Changed in <<reconfigure, reconfigure>>

| cleanerManager
a| [[cleanerManager]] <<kafka-log-LogCleanerManager.adoc#, LogCleanerManager>>

|===

[[logging]]
[TIP]
====
Enable `WARN` or `INFO` logging levels for `kafka.log.LogCleaner` logger to see what happens inside.

Add the following line to `config/log4j.properties`:

```
log4j.logger.kafka.log.LogCleaner=INFO
```

Refer to link:kafka-logging.adoc[Logging].

---

Please note that Kafka comes with a preconfigured `kafka.log.LogCleaner` logger in `config/log4j.properties`:

```
log4j.appender.cleanerAppender=org.apache.log4j.DailyRollingFileAppender
log4j.appender.cleanerAppender.DatePattern='.'yyyy-MM-dd-HH
log4j.appender.cleanerAppender.File=${kafka.logs.dir}/log-cleaner.log
log4j.appender.cleanerAppender.layout=org.apache.log4j.PatternLayout
log4j.appender.cleanerAppender.layout.ConversionPattern=[%d] %p %m (%c)%n

log4j.logger.kafka.log.LogCleaner=INFO, cleanerAppender
log4j.additivity.kafka.log.LogCleaner=false
```

That means that the logs of `LogCleaner` go to `logs/log-cleaner.log` file at `INFO` logging level and are not added to the main logs (per `log4j.additivity` being off).
====

=== [[createNewCleanedSegment]] `createNewCleanedSegment` Method

[source, scala]
----
createNewCleanedSegment(log: Log, baseOffset: Long): LogSegment
----

`createNewCleanedSegment`...FIXME

NOTE: `createNewCleanedSegment` is used when...FIXME

=== [[cleanSegments]] `cleanSegments` Internal Method

[source, scala]
----
cleanSegments(
  log: Log,
  segments: Seq[LogSegment],
  map: OffsetMap,
  deleteHorizonMs: Long,
  stats: CleanerStats): Unit
----

`cleanSegments`...FIXME

NOTE: `cleanSegments` is used when...FIXME

=== [[buildOffsetMap]] `buildOffsetMap` Internal Method

[source, scala]
----
buildOffsetMap(
  log: Log,
  start: Long,
  end: Long,
  map: OffsetMap,
  stats: CleanerStats): Unit
----

`buildOffsetMap`...FIXME

NOTE: `buildOffsetMap` is used when...FIXME

=== [[reconfigure]] Reconfiguring -- `reconfigure` Method

[source, scala]
----
reconfigure(oldConfig: KafkaConfig, newConfig: KafkaConfig): Unit
----

NOTE: `reconfigure` is part of the <<kafka-server-BrokerReconfigurable.adoc#reconfigure, BrokerReconfigurable Contract>> to change (_reconfigure_) the value of a Kafka dynamic configuration.

`reconfigure`...FIXME

=== [[creating-instance]] Creating LogCleaner Instance

`LogCleaner` takes the following to be created:

* [[initialConfig]] <<CleanerConfig, CleanerConfig>>
* [[logDirs]] Data log directories
* [[logs]] <<kafka-log-Log.adoc#, Logs>> per Kafka `TopicPartition`
* [[logDirFailureChannel]] `LogDirFailureChannel`
* [[time]] `Time`

`LogCleaner` initializes the <<internal-registries, internal registries and counters>>.

=== [[startup]] Starting Up -- `startup` Method

[source, scala]
----
startup(): Unit
----

`startup` prints out the following INFO message to the logs:

```
Starting the log cleaner
```

`startup` creates new <<kafka-log-CleanerThread.adoc#, CleanerThreads>> and <<kafka-log-CleanerThread.adoc#doWork, starts>> them all immediately.

`startup` adds the cleaner threads in <<cleaners, cleaners>> internal registry.

NOTE: The number of `CleanerThreads` is controlled by <<numThreads, log.cleaner.threads>> dynamic configuration (default: `1`).

[NOTE]
====
`startup` is used when:

* `LogManager` is requested to <<kafka-log-LogManager.adoc#startup, start up>> (with `enableCleaner` enabled which is the default)

* `LogCleaner` is requested to <<reconfigure, reconfigure>>
====

=== [[cleanerConfig]] Building CleanerConfig From KafkaConfig -- `cleanerConfig` Method

[source, scala]
----
cleanerConfig(config: KafkaConfig): CleanerConfig
----

`cleanerConfig` simply creates a <<CleanerConfig, CleanerConfig>> from the given <<kafka-server-KafkaConfig.adoc#, KafkaConfig>>.

[NOTE]
====
`cleanerConfig` is used when:

* `LogCleaner` is requested to <<validateReconfiguration, validateReconfiguration>> and <<reconfigure, reconfigure>>

* `LogManager` is <<kafka-log-LogManager.adoc#apply, created>>
====

=== [[CleanerConfig]] `CleanerConfig`

`CleanerConfig` represents a set of <<reconfigurableConfigs, dynamic configurations>> of a <<config, LogCleaner>>:

* [[numThreads]] <<kafka-server-KafkaConfig.adoc#logCleanerThreads, log.cleaner.threads>> (default: `1`)
* [[dedupeBufferSize]] <<kafka-server-KafkaConfig.adoc#logCleanerDedupeBufferSize, dedupeBufferSize>> (default: `4*1024*1024L`)
* [[dedupeBufferLoadFactor]] <<kafka-server-KafkaConfig.adoc#logCleanerDedupeBufferLoadFactor, dedupeBufferLoadFactor>> (default: `0.9d`)
* [[ioBufferSize]] <<kafka-server-KafkaConfig.adoc#logCleanerIoBufferSize, ioBufferSize>> (default: `1024*1024`)
* [[maxMessageSize]] <<kafka-server-KafkaConfig.adoc#logCleanerIoBufferSize, maxMessageSize>> (default: `32*1024*1024`)
* [[maxIoBytesPerSecond]] <<kafka-server-KafkaConfig.adoc#logCleanerIoMaxBytesPerSecond, maxIoBytesPerSecond>> (default: `Double.MaxValue`)
* [[backOffMs]] <<kafka-server-KafkaConfig.adoc#logCleanerBackoffMs, backOffMs>> (default: `15 * 1000`)
* [[enableCleaner]] <<kafka-server-KafkaConfig.adoc#logCleanerEnable, enableCleaner>> flag (default: `true`)
* [[hashAlgorithm]] `hashAlgorithm` (default: `MD5`)

`CleanerConfig` is created exclusively when `LogCleaner` is requested to <<cleanerConfig, build a CleanerConfig from a KafkaConfig>>.
