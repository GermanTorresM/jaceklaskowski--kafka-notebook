== [[LogManager]] LogManager

`LogManager` is <<creating-instance, created>> and immediately <<startup, started>> when `KafkaServer` is requested to <<kafka-KafkaServer.adoc#startup, start up>>.

.LogManager and KafkaServer
image::images/LogManager.png[align="center"]

`LogManager` manages the <<logDirs, log directories>> that are configured using <<kafka-KafkaConfig.adoc#logDirs, log.dirs or log.dir>> configuration properties (default: <<kafka-properties.adoc#log.dir, /tmp/kafka-logs>>).

`LogManager` is used to create a <<kafka-server-ReplicaManager.adoc#logManager, ReplicaManager>>, a `DynamicLogConfig`, a `TopicConfigHandler`.

[[internal-registries]]
.LogManager's Internal Properties (e.g. Registries, Counters and Flags)
[cols="1m,2",options="header",width="100%"]
|===
| Name
| Description

| _liveLogDirs
| [[_liveLogDirs]] Java's https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ConcurrentLinkedQueue.html[ConcurrentLinkedQueue] of log directories

Used when...FIXME
|===

[[logging]]
[TIP]
====
Enable `INFO` or `DEBUG` logging level for `kafka.log.LogManager` logger to see what happens inside.

Add the following line to `config/log4j.properties`:

```
log4j.logger.kafka.log.LogManager=DEBUG, stdout
```

Refer to link:kafka-logging.adoc[Logging].
====

=== [[startup]] Starting Up -- `startup` Method

[source, scala]
----
startup(): Unit
----

`startup`...FIXME

NOTE: `startup` is used when...FIXME

=== [[allLogs]] Getting All Partition Logs -- `allLogs` Method

[source, scala]
----
allLogs: Iterable[Log]
----

`allLogs`...FIXME

NOTE: `allLogs` is used when...FIXME

=== [[addLogToBeDeleted]] `addLogToBeDeleted` Internal Method

[source, scala]
----
addLogToBeDeleted(log: Log): Unit
----

`addLogToBeDeleted`...FIXME

NOTE: `addLogToBeDeleted` is used when...FIXME

=== [[asyncDelete]] `asyncDelete` Method

[source, scala]
----
asyncDelete(topicPartition: TopicPartition, isFuture: Boolean = false): Log
----

`asyncDelete`...FIXME

NOTE: `asyncDelete` is used when...FIXME

=== [[getOrCreateLog]] `getOrCreateLog` Method

[source, scala]
----
getOrCreateLog(
  topicPartition: TopicPartition,
  config: LogConfig,
  isNew: Boolean = false,
  isFuture: Boolean = false): Log
----

`getOrCreateLog`...FIXME

NOTE: `getOrCreateLog` is used exclusively when `Partition` is requested to <<kafka-cluster-Partition.adoc#getOrCreateReplica, getOrCreateReplica>>.

=== [[loadLog]] `loadLog` Internal Method

[source, scala]
----
loadLog(
  logDir: File,
  recoveryPoints: Map[TopicPartition, Long],
  logStartOffsets: Map[TopicPartition, Long]): Unit
----

`loadLog`...FIXME

NOTE: `loadLog` is used exclusively when `LogManager` is requested to <<loadLogs, loadLogs>>.

=== [[loadLogs]] Loading Logs -- `loadLogs` Internal Method

[source, scala]
----
loadLogs(): Unit
----

`loadLogs` prints out the following INFO message to the logs:

```
Loading logs.
```

For every <<liveLogDirs, live log directory>>, `loadLogs`...FIXME

NOTE: `loadLogs` is used exclusively when `LogManager` is <<creating-instance, created>>.

=== [[creating-instance]] Creating LogManager Instance

`LogManager` takes the following when created:

* [[logDirs]] Log directories
* [[initialOfflineDirs]] Initial offline directories
* [[topicConfigs]] Topic configurations (`Map[String, LogConfig]`)
* [[initialDefaultConfig]] Initial default configuration (`LogConfig`)
* [[cleanerConfig]] `CleanerConfig`
* [[recoveryThreadsPerDataDir]] `recoveryThreadsPerDataDir`
* [[flushCheckMs]] `flushCheckMs`
* [[flushRecoveryOffsetCheckpointMs]] `flushRecoveryOffsetCheckpointMs`
* [[flushStartOffsetCheckpointMs]] `flushStartOffsetCheckpointMs`
* [[retentionCheckMs]] `retentionCheckMs`
* [[maxPidExpirationMs]] `maxPidExpirationMs`
* [[scheduler]] <<kafka-Scheduler.adoc#, Scheduler>>
* [[brokerState]] `BrokerState`
* [[brokerTopicStats]] <<kafka-BrokerTopicStats.adoc#, BrokerTopicStats>>
* [[logDirFailureChannel]] `LogDirFailureChannel`
* [[time]] `Time`

`LogManager` initializes the <<internal-registries, internal registries and counters>>.

While being created, `LogManager` <<loadLogs, load logs>>.

=== [[apply]] Creating LogManager -- `apply` Factory Method

[source, scala]
----
apply(
  config: KafkaConfig,
  initialOfflineDirs: Seq[String],
  zkClient: KafkaZkClient,
  brokerState: BrokerState,
  kafkaScheduler: KafkaScheduler,
  time: Time,
  brokerTopicStats: BrokerTopicStats,
  logDirFailureChannel: LogDirFailureChannel): LogManager
----

`apply`...FIXME

NOTE: `apply` is used exclusively when `KafkaServer` is requested to <<kafka-KafkaServer.adoc#startup, start up>>.

=== [[liveLogDirs]] `liveLogDirs` Method

[source, scala]
----
liveLogDirs: Seq[File]
----

`liveLogDirs`...FIXME

NOTE: `liveLogDirs` is used when...FIXME
