== [[KafkaServer]] KafkaServer

`KafkaServer` is a Kafka broker that wires (creates and starts) Kafka services together.

.KafkaServer's Startup and Auxiliary Services
image::images/KafkaServer-startup.png[align="center"]

`KafkaServer` <<creating-instance, registers itself in the JMX system>> under *kafka.server*.

[[internal-registries]]
.KafkaServer's Internal Properties (e.g. Registries and Counters)
[cols="1,2",options="header",width="100%"]
|===
| Name
| Description

| [[adminManager]] `adminManager`
| link:kafka-AdminManager.adoc[AdminManager]

| [[apis]] `apis`
| link:kafka-KafkaApis.adoc[KafkaApis]

| [[authorizer]] `authorizer`
| Optional link:kafka-Authorizer.adoc[Authorizer]

| `brokerMetadataCheckpoints`
| [[brokerMetadataCheckpoints]]

| [[brokerState]] `brokerState`
| `BrokerState`

| [[_brokerTopicStats]] `_brokerTopicStats`
| `BrokerTopicStats`

| [[_clusterId]] `_clusterId`
| Cluster ID

| [[credentialProvider]] `credentialProvider`
| `CredentialProvider`

| [[dynamicConfigHandlers]] `dynamicConfigHandlers`
|

| [[dynamicConfigManager]] `dynamicConfigManager`
| link:kafka-DynamicConfigManager.adoc[DynamicConfigManager]

| [[groupCoordinator]] `groupCoordinator`
| link:kafka-GroupCoordinator.adoc[GroupCoordinator]

| [[isStartingUp]] `isStartingUp`
| Flag for...FIXME

| [[kafkaController]] `kafkaController`
| link:kafka-KafkaController.adoc[KafkaController]

| [[kafkaHealthcheck]] `kafkaHealthcheck`
| link:kafka-KafkaHealthcheck.adoc[KafkaHealthcheck]

| `kafkaScheduler`
| [[kafkaScheduler]] <<kafka-KafkaScheduler.adoc#, KafkaScheduler>> with the number of daemon threads as configured using <<kafka-properties.adoc#backgroundThreads, background.threads>> configuration property (default: `10`)

| [[logContext]] `logContext`
| `LogContext`

| [[logDirFailureChannel]] `logDirFailureChannel`
| `LogDirFailureChannel`

| `logManager`
a| [[logManager]][[getLogManager]] <<kafka-LogManager.adoc#, LogManager>>

Used when:

* <<checkpointBrokerId, checkpointBrokerId>> (when `KafkaServer` is requested to <<startup, start up>>)

* `DynamicBrokerConfig` is requested to <<kafka-DynamicBrokerConfig.adoc#addReconfigurables, addReconfigurables>>

* `KafkaServer` is requested to <<startup, start up>> (and creates a `TopicConfigHandler` for topics for <<dynamicConfigHandlers, dynamicConfigHandlers>> and a <<createReplicaManager, ReplicaManager>>)

---

<<kafka-LogManager.adoc#apply, Created>> and immediately <<kafka-LogManager.adoc#startup, started>> when `KafkaServer` is requested to <<startup, start up>>.

<<kafka-LogManager.adoc#shutdown, Shut down>> when `KafkaServer` is requested to <<shutdown, shut down>>.

| [[metadataCache]] `metadataCache`
| link:kafka-MetadataCache.adoc[MetadataCache]

| [[replicaManager]] `replicaManager`
a| <<kafka-server-ReplicaManager.adoc#, ReplicaManager>> used to create:

* <<apis, KafkaApis>>
* <<groupCoordinator, GroupCoordinator>>
* <<transactionCoordinator, TransactionCoordinator>>

---

* link:kafka-server-ReplicaManager.adoc#creating-instance[Created] (and link:kafka-server-ReplicaManager.adoc#startup[started] immmediately) when `KafkaServer` is requested to <<startup, start up>>

* link:kafka-server-ReplicaManager.adoc#shutdown[Shut down] when `KafkaServer` <<shutdown, shuts down>>

| [[reporters]] `reporters`
| Collection of link:kafka-MetricsReporter.adoc[MetricsReporter]

Used when...FIXME

| [[requestHandlerPool]] `requestHandlerPool`
| link:kafka-KafkaRequestHandlerPool.adoc[KafkaRequestHandlerPool]

| [[socketServer]] `socketServer`
| link:kafka-SocketServer.adoc[SocketServer]

| [[transactionCoordinator]] `transactionCoordinator`
| link:kafka-TransactionCoordinator.adoc[TransactionCoordinator]

| [[quotaManagers]] `quotaManagers`
| `QuotaManagers`

| [[shutdownLatch]] `shutdownLatch`
| Java's https://docs.oracle.com/javase/9/docs/api/java/util/concurrent/CountDownLatch.html[java.util.concurrentCountDownLatch]

| [[startupComplete]] `startupComplete`
| Flag for...FIXME

| [[zkUtils]] `zkUtils`
| link:kafka-ZkUtils.adoc[ZkUtils]
|===

=== [[getBrokerIdAndOfflineDirs]] Getting Broker ID and Initial Offline Directories -- `getBrokerIdAndOfflineDirs` Internal Method

[source, scala]
----
getBrokerIdAndOfflineDirs: (Int, Seq[String])
----

`getBrokerIdAndOfflineDirs`...FIXME

NOTE: `getBrokerIdAndOfflineDirs` is used when...FIXME

=== [[getOrGenerateClusterId]] `getOrGenerateClusterId` Internal Method

CAUTION: FIXME

=== [[initZk]] Connecting to Zookeeper -- `initZk` Internal Method

CAUTION: FIXME

=== [[checkpointBrokerId]] `checkpointBrokerId` Internal Method

[source, scala]
----
checkpointBrokerId(brokerId: Int): Unit
----

`checkpointBrokerId`...FIXME

NOTE: `checkpointBrokerId` is used exclusively when `KafkaServer` is requested to <<startup, start up>>.

=== [[creating-instance]] Creating KafkaServer Instance

`KafkaServer` takes the following when created:

* [[config]] link:kafka-KafkaConfig.adoc[KafkaConfig]
* [[time]] `Time` (defaults to `Time.SYSTEM`)
* [[threadNamePrefix]] Optional thread name prefix
* [[kafkaMetricsReporters]] A collection of link:kafka-KafkaMetricsReporter.adoc[KafkaMetricsReporters] (defaults to no reporters)

CAUTION: FIXME

NOTE: `KafkaServer` is created when link:kafka-KafkaServerStartable.adoc#creating-instance[`KafkaServerStartable` is created].

=== [[startup]] Starting Up -- `startup` Method

[source, scala]
----
startup(): Unit
----

`startup` starts a single Kafka server.

Internally, `startup` first prints out the following INFO message to the logs:

```
INFO starting (kafka.server.KafkaServer)
```

`startup` sets <<brokerState, BrokerState>> as `Starting`.

`startup` requests <<kafkaScheduler, KafkaScheduler>> to link:kafka-KafkaScheduler.adoc#startup[start].

`startup` <<initZk, connects to Zookeeper>> (and initializes <<zkUtils, ZkUtils>>).

`startup` <<getOrGenerateClusterId, getOrGenerateClusterId>> (that is recorded as <<_clusterId, cluster id>>).

You should see the following INFO message in the logs:

```
INFO Cluster ID = [clusterId] (kafka.server.KafkaServer)
```

`startup` <<getBrokerIdAndOfflineDirs, gets broker id and initial offline directories>>.

`startup` creates the `LogContext` with *[KafkaServer id=[brokerId]]* prefix.

`startup` creates and configures metrics.

1. Requests <<config, KafkaConfig>> for link:kafka-KafkaConfig.adoc#getConfiguredInstances[configured instances] of metric reporters

1. Adds a `JmxReporter` (with *kafka.server* prefix)

1. Creates the `MetricConfig`

1. Initializes <<metrics, Metrics>> internal registry

`startup` registers broker topic metrics (by initializing <<_brokerTopicStats, BrokerTopicStats>>).

`startup` initializes <<quotaManagers, QuotaManagers>>.

`startup` <<notifyClusterListeners, notifies cluster resource listeners>> (i.e. <<kafkaMetricsReporters, KafkaMetricsReporters>> and the configured instances of metric reporters).

`startup` creates the <<logDirFailureChannel, LogDirFailureChannel>>

`startup` creates the <<logManager, LogManager>> and requests it to link:kafka-LogManager.adoc#startup[start up].

`startup` creates the <<metadataCache, MetadataCache>> (for the <<brokerId, broker ID>>).

`startup` creates the <<credentialProvider, CredentialProvider>> (per link:kafka-properties.adoc#sasl.enabled.mechanisms[sasl.enabled.mechanisms] property).

`startup` creates the <<socketServer, SocketServer>> (for <<config, KafkaConfig>>, <<metrics, Metrics>> and <<credentialProvider, CredentialProvider>>) and requests it to link:kafka-SocketServer.adoc#startup[start up].

`startup` creates the <<replicaManager, ReplicaManager>> and requests it to link:kafka-server-ReplicaManager.adoc#startup[start up].

`startup` link:kafka-KafkaController.adoc#creating-instance[creates] the <<kafkaController, KafkaController>> (for <<config, KafkaConfig>>, <<zkUtils, ZkUtils>>, <<metrics, Metrics>> and the optional <<threadNamePrefix, threadNamePrefix>>) and requests it to link:kafka-KafkaController.adoc#startup[start up].

`startup` link:kafka-AdminManager.adoc#creating-instance[creates] the <<adminManager, AdminManager>> (for <<config, KafkaConfig>>, <<metrics, Metrics>>, <<metadataCache, MetadataCache>> and <<zkUtils, ZkUtils>>).

`startup` link:kafka-GroupCoordinator.adoc#creating-instance[creates] the <<groupCoordinator, GroupCoordinator>> (for <<config, KafkaConfig>>, <<zkUtils, ZkUtils>> and <<replicaManager, ReplicaManager>>) and requests it to link:kafka-GroupCoordinator.adoc#startup[start up].

`startup` link:kafka-TransactionCoordinator.adoc#creating-instance[creates] the <<transactionCoordinator, TransactionCoordinator>> (for <<config, KafkaConfig>>, <<replicaManager, ReplicaManager>>, a new dedicated link:kafka-KafkaScheduler.adoc[KafkaScheduler] with `transaction-log-manager-` thread name prefix, <<zkUtils, ZkUtils>>, <<metrics, Metrics>> and <<metadataCache, MetadataCache>>) and requests it to link:kafka-TransactionCoordinator.adoc#startup[start up].

`startup` creates a <<authorizer, Authorizer>> (if defined using link:kafka-properties.adoc#authorizer.class.name[authorizer.class.name] property) and link:kafka-Authorizer.adoc#configure[configures] it.

`startup` link:kafka-KafkaApis.adoc#creating-instance[creates] the <<apis, KafkaApis>> (for <<socketServer, SocketServer>>, <<replicaManager, ReplicaManager>>, <<adminManager, AdminManager>>, <<groupCoordinator, GroupCoordinator>>, <<transactionCoordinator, TransactionCoordinator>>, <<kafkaController, KafkaController>>, <<zkUtils, ZkUtils>>, <<brokerId, broker ID>>, <<config, KafkaConfig>>, <<metadataCache, MetadataCache>>, <<metrics, Metrics>>, <<authorizer, Authorizer>>, <<quotaManagers, QuotaManagers>>, <<_brokerTopicStats, BrokerTopicStats>>, <<clusterId, cluster ID>>).

NOTE: At this point `KafkaServer` may start processing requests.

`startup` link:kafka-KafkaRequestHandlerPool.adoc#creating-instance[creates] the <<requestHandlerPool, KafkaRequestHandlerPool>> (for <<brokerId, broker ID>>, <<socketServer, SocketServer>>, <<apis, KafkaApis>> and link:kafka-properties.adoc#num.io.threads[num.io.threads]).

`startup` starts the HTTP interface of mx4j (if configured).

`startup` creates the <<dynamicConfigManager, DynamicConfigManager>> (for <<zkUtils, ZkUtils>> and <<dynamicConfigHandlers, dynamicConfigHandlers>>) and requests it to link:kafka-DynamicConfigManager.adoc#startup[start up].

`startup` configures the advertised listeners (if defined).

`startup` creates the <<kafkaHealthcheck, KafkaHealthcheck>> (for <<brokerId, broker ID>>, the advertised listeners, <<zkUtils, ZkUtils>>, link:kafka-properties.adoc#broker.rack[broker.rack] and link:kafka-properties.adoc#inter.broker.protocol.version[inter.broker.protocol.version] Kafka properties) and requests it to link:kafka-KafkaHealthcheck.adoc#startup[start up].

`startup` <<checkpointBrokerId, checkpoints>> the <<brokerId, broker ID>>.

`startup` sets <<brokerState, BrokerState>> as `RunningAsBroker`, creates the <<shutdownLatch, CountDownLatch>>, enables the <<startupComplete, startupComplete>> flag, disables <<isStartingUp, isStartingUp>> flag

`startup` registers `AppInfo` as an MBean with the MBean server as `kafka.server:type=app-info,id=[brokerId]`.

In the end, you should see the following INFO message in the logs:

```
INFO [Kafka Server [brokerId]], started (kafka.server.KafkaServer)
```

NOTE: The INFO message above uses so-called *log ident* with the value of `broker.id` property and is always in the format ``[Kafka Server [brokerId]], `` after a Kafka server has fully started.

NOTE: `startup` is used exclusively when `KafkaServerStartable` link:kafka-KafkaServerStartable.adoc#startup[starts up].

=== [[notifyClusterListeners]] Sending Updated Cluster Metadata to ClusterResourceListeners -- `notifyClusterListeners` Internal Method

[source, scala]
----
notifyClusterListeners(clusterListeners: Seq[AnyRef]): Unit
----

`notifyClusterListeners` creates a link:kafka-ClusterResourceListener.adoc#ClusterResourceListeners[ClusterResourceListeners] (with the objects from the input `clusterListeners` of type `ClusterResourceListener`) and link:kafka-ClusterResourceListener.adoc#onUpdate[sends the updated cluster metadata] to them.

NOTE: `notifyClusterListeners` is used exclusively when `KafkaServer` <<startup, starts up>> (with `clusterListeners` as <<kafkaMetricsReporters, kafkaMetricsReporters>> and the `MetricsReporter` reporters from link:kafka-properties.adoc#metric_reporters[metric.reporters] Kafka property).

=== [[createReplicaManager]] Creating ReplicaManager -- `createReplicaManager` Internal Method

[source, scala]
----
createReplicaManager(isShuttingDown: AtomicBoolean): ReplicaManager
----

`createReplicaManager` simply link:kafka-server-ReplicaManager.adoc#creating-instance[creates] the <<replicaManager, ReplicaManager>> (passing in the references to the services, e.g. <<metrics, Metrics>>, <<kafkaScheduler, KafkaScheduler>>, <<logManager, LogManager>>, <<quotaManagers, QuotaManagers>>, <<metadataCache, MetadataCache>>, <<logDirFailureChannel, LogDirFailureChannel>>).

NOTE: `createReplicaManager` is used exclusively when `KafkaServer` is requested to <<startup, start up>>.

=== [[shutdown]] `shutdown` Method

[source, scala]
----
shutdown(): Unit
----

`shutdown`...FIXME

NOTE: `shutdown` is used when...FIXME
